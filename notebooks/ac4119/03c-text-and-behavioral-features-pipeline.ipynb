{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries & UDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "from ttictoc import Timer\n",
    "import pickle\n",
    "import json\n",
    "from ast import literal_eval\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, average_precision_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base = '/Users/chuamelia/Google Drive/Spring 2020/Machine Learning/fake-review-detection-project/data/processed/dev/'\n",
    "\n",
    "def load_obj(fname,  base=base):\n",
    "    # This loads the pickled object.\n",
    "    with open(base + fname + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def writeJsonFile(fname, data,  base=base):\n",
    "    with open(base + fname +'.json', 'w') as outfile:\n",
    "        json.dump(data, outfile)\n",
    "    print('Successfully written to {}'.format(fname))\n",
    "    \n",
    "def readJsonFile(fname, base=base):\n",
    "    with open(base + fname + '.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def identity_tokenizer(tokens):\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ClassifierMetrics (X_train, Y_train, X_test, Y_test, fitted_model):\n",
    "    Y_pred = fitted_model.predict(X_test)\n",
    "    Y_score = fitted_model.decision_function(X_test)\n",
    "    metrics = {'train_accuracy': fitted_model.score(X_train, Y_train),\n",
    "               'test_accuracy': fitted_model.score(X_test, Y_test),\n",
    "               'test_auc_pred': roc_auc_score(Y_test, Y_pred),\n",
    "               'test_auc_score': roc_auc_score(Y_test, Y_score),\n",
    "               'test_ap_pred': average_precision_score(Y_test, Y_pred),\n",
    "               'test_ap_score': average_precision_score(Y_test, Y_score)}\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 3\n",
    "dev_name = 'ac4119_dev_w_tokens'\n",
    "\n",
    "train_fname = '../../data/processed/dev/ac4119_train_set_{0}_w_tokens.csv'.format(i)\n",
    "dev_fname = '../../data/processed/dev/{0}.csv'.format(dev_name)\n",
    "\n",
    "train = pd.read_csv(train_fname)\n",
    "dev = pd.read_csv(dev_fname)\n",
    "\n",
    "Y_train = train['label']\n",
    "Y_dev = dev['label']\n",
    "\n",
    "tfidf_vectorizer_fname = 'ac4119_X_train_set_{0}_tfidf_vectorizer'.format(i)\n",
    "tfidf_vectorizer = load_obj(tfidf_vectorizer_fname)\n",
    "\n",
    "train['token_review'] = train['token_review'].apply(lambda x: literal_eval(x))\n",
    "dev['token_review'] = dev['token_review'].apply(lambda x: literal_eval(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Joining Lookup Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_reviews_by_user = pd.read_csv(base + 'num_reviews_by_user.csv')\n",
    "num_reviews_by_prod = pd.read_csv(base + 'num_reviews_by_prod.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rationale: \n",
    "# At train, you only have visibility to the training numbers to train your model\n",
    "train_num_reviews_by_user = num_reviews_by_user[['user_id','train_num_reviews']]\n",
    "train_num_reviews_by_user.columns = ['user_id','num_user_reviews']\n",
    "# However, at dev/test you will have the cumulative numbers as INPUT ONLY.\n",
    "# We cannot use the cumulative number(s) to generate our model. \n",
    "# But, realistic to use them as input during test/dev\n",
    "dev_num_reviews_by_user = num_reviews_by_user[['user_id','cumulative_total_train_dev_test_reviews']]\n",
    "dev_num_reviews_by_user.columns = ['user_id','num_user_reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_num_reviews_by_prod = num_reviews_by_prod[['prod_id','train_num_reviews']]\n",
    "train_num_reviews_by_prod.columns = ['prod_id','num_prod_reviews']\n",
    "\n",
    "dev_num_reviews_by_prod = num_reviews_by_prod[['prod_id','cumulative_total_train_dev_test_reviews']]\n",
    "dev_num_reviews_by_prod.columns = ['prod_id','num_prod_reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train, train_num_reviews_by_user , on='user_id', how='left')\n",
    "train = pd.merge(train, train_num_reviews_by_prod , on='prod_id', how='left')\n",
    "\n",
    "dev = pd.merge(dev, dev_num_reviews_by_user , on='user_id', how='left')\n",
    "dev = pd.merge(dev, dev_num_reviews_by_prod , on='prod_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "feature_cols = ['rating', 'token_review', 'num_user_reviews', 'num_prod_reviews']\n",
    "X_train = train[feature_cols].fillna(0)\n",
    "X_dev = dev[feature_cols].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = train['label']\n",
    "Y_dev = dev['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining tfidf params\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=identity_tokenizer, decode_error='ignore',\n",
    "                                       stop_words='english', \n",
    "                                       lowercase=False, binary=True, \n",
    "                                       min_df=0.01)\n",
    "# Defining model params\n",
    "\n",
    "params = {'alpha': 0.0001,\n",
    "  'class_weight': 'balanced',\n",
    "  'loss': 'log',\n",
    "  'penalty': 'l2',\n",
    "  'random_state': 519}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "# setting remainder to passthrough so that the remaining columns (i.e. rating) get included as-is \n",
    "pipeline = Pipeline([\n",
    "    ('transformer',  make_column_transformer((StandardScaler(), ['num_user_reviews', 'num_prod_reviews']),\n",
    "                                            (tfidf_vectorizer, 'token_review'),\n",
    "                                            remainder = 'passthrough')),\n",
    "    ('fitted_svm', SGDClassifier(**params)),\n",
    "])\n",
    "\n",
    "fitted_model = pipeline.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics = ClassifierMetrics(X_train, Y_train, X_dev, Y_dev, fitted_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_accuracy': 0.6988418063366557,\n",
       " 'test_ap_pred': 0.17485633426942299,\n",
       " 'test_ap_score': 0.24497013129895262,\n",
       " 'test_auc_pred': 0.6969727226145626,\n",
       " 'test_auc_score': 0.7632626849118458,\n",
       " 'train_accuracy': 0.7032534320265095}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_fname = '../../data/processed/dev/ac4119_test_set_w_tokens.csv'\n",
    "test = pd.read_csv(test_fname)\n",
    "test_num_reviews_by_prod = num_reviews_by_prod[['prod_id','cumulative_total_train_dev_test_reviews']]\n",
    "test_num_reviews_by_prod.columns = ['prod_id','num_prod_reviews']\n",
    "\n",
    "test_num_reviews_by_user = num_reviews_by_user[['user_id','cumulative_total_train_dev_test_reviews']]\n",
    "test_num_reviews_by_user.columns = ['user_id','num_user_reviews']\n",
    "\n",
    "test = pd.merge(test, test_num_reviews_by_user , on='user_id', how='left')\n",
    "test = pd.merge(test, test_num_reviews_by_prod , on='prod_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['token_review'] = test['token_review'].apply(lambda x: literal_eval(x))\n",
    "\n",
    "feature_cols = ['rating', 'token_review', 'num_user_reviews', 'num_prod_reviews']\n",
    "X_test = test[feature_cols].fillna(0)\n",
    "\n",
    "Y_test = test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = fitted_model.predict(X_test)\n",
    "Y_score = fitted_model.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46474"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Y_score'] = Y_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ex_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>prod_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>date</th>\n",
       "      <th>review</th>\n",
       "      <th>token_review</th>\n",
       "      <th>num_user_reviews</th>\n",
       "      <th>num_prod_reviews</th>\n",
       "      <th>Y_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>929</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-08-25</td>\n",
       "      <td>Let me start with a shout-out to everyone who ...</td>\n",
       "      <td>[let, start, shout, boosting, mint, lemonade, ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>-0.153497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>932</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-05-09</td>\n",
       "      <td>Stopped in for lunch today and couldn't believ...</td>\n",
       "      <td>[stopped, lunch, today, believe, boyfriend, sh...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>-0.195586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>937</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-10-15</td>\n",
       "      <td>Tiny little place, but very good food. Pastits...</td>\n",
       "      <td>[tiny, pastitsio, especially]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0.396291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>945</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-04-10</td>\n",
       "      <td>Food was delicious and service was great. Good...</td>\n",
       "      <td>[atmosphere, quick, bite, catch]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0.686363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>946</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-03-29</td>\n",
       "      <td>Awesome hole in the wall place to grab a quick...</td>\n",
       "      <td>[awesome, hole, wall, grab, quick, bite, music...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>-0.261937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ex_id  user_id  prod_id  rating  label        date  \\\n",
       "0      6      929        0     4.0    NaN  2009-08-25   \n",
       "1      9      932        0     5.0    NaN  2014-05-09   \n",
       "2     14      937        0     4.0    NaN  2014-10-15   \n",
       "3     22      945        0     5.0    NaN  2014-04-10   \n",
       "4     23      946        0     5.0    NaN  2014-03-29   \n",
       "\n",
       "                                              review  \\\n",
       "0  Let me start with a shout-out to everyone who ...   \n",
       "1  Stopped in for lunch today and couldn't believ...   \n",
       "2  Tiny little place, but very good food. Pastits...   \n",
       "3  Food was delicious and service was great. Good...   \n",
       "4  Awesome hole in the wall place to grab a quick...   \n",
       "\n",
       "                                        token_review  num_user_reviews  \\\n",
       "0  [let, start, shout, boosting, mint, lemonade, ...               1.0   \n",
       "1  [stopped, lunch, today, believe, boyfriend, sh...               1.0   \n",
       "2                      [tiny, pastitsio, especially]               2.0   \n",
       "3                   [atmosphere, quick, bite, catch]               1.0   \n",
       "4  [awesome, hole, wall, grab, quick, bite, music...               3.0   \n",
       "\n",
       "   num_prod_reviews   Y_score  \n",
       "0             210.0 -0.153497  \n",
       "1             210.0 -0.195586  \n",
       "2             210.0  0.396291  \n",
       "3             210.0  0.686363  \n",
       "4             210.0 -0.261937  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = test[['ex_id', 'Y_score']].sort_values(by='ex_id', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ex_id</th>\n",
       "      <th>Y_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>-0.153497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>-0.195586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>0.396291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>0.686363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>-0.261937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ex_id   Y_score\n",
       "0      6 -0.153497\n",
       "1      9 -0.195586\n",
       "2     14  0.396291\n",
       "3     22  0.686363\n",
       "4     23 -0.261937"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chuamelia/Google Drive/Spring 2020/Machine Learning/fake-review-detection-project/notebooks/ac4119\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = '/Users/chuamelia/Google Drive/Spring 2020/Machine Learning/fake-review-detection-project/predictions.csv'\n",
    "predictions['Y_score'].to_csv(fname, header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
