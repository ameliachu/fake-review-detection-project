{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries & UDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ttictoc import Timer\n",
    "import pickle\n",
    "import json\n",
    "from ast import literal_eval\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base = '/Users/chuamelia/Google Drive/Spring 2020/Machine Learning/fake-review-detection-project/data/processed/dev/'\n",
    "\n",
    "def load_obj(fname,  base=base):\n",
    "    # This loads the pickled object.\n",
    "    with open(base + fname + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def writeJsonFile(fname, data,  base=base):\n",
    "    with open(base + fname +'.json', 'w') as outfile:\n",
    "        json.dump(data, outfile)\n",
    "    print('Successfully written to {}'.format(fname))\n",
    "    \n",
    "def readJsonFile(fname, base=base):\n",
    "    with open(base + fname + '.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def identity_tokenizer(tokens):\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ClassifierMetrics (X_train, Y_train, X_test, Y_test, fitted_model):\n",
    "    Y_pred = fitted_model.predict(X_test)\n",
    "    Y_score = fitted_model.decision_function(X_test)\n",
    "    metrics = {'train_accuracy': fitted_model.score(X_train, Y_train),\n",
    "               'test_accuracy': fitted_model.score(X_test, Y_test),\n",
    "               'test_auc_pred': roc_auc_score(Y_test, Y_pred),\n",
    "               'test_auc_score': roc_auc_score(Y_test, Y_score),\n",
    "               'test_ap_pred': average_precision_score(Y_test, Y_pred),\n",
    "               'test_ap_score': average_precision_score(Y_test, Y_score)}\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading in Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lookup Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_reviews_by_user = pd.read_csv(base + 'num_reviews_by_user.csv')\n",
    "num_reviews_by_prod = pd.read_csv(base + 'num_reviews_by_prod.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Construct Dev Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_fname = '../../data/processed/dev/ac4119_dev_w_tokens.csv'\n",
    "dev = pd.read_csv(dev_fname)\n",
    "\n",
    "dev['token_review'] = dev['token_review'].apply(lambda x: literal_eval(x))\n",
    "# Rationale: \n",
    "# At train, you only have visibility to the training numbers to train your model\n",
    "# However, at dev/test you will have the cumulative numbers as INPUT ONLY.\n",
    "# We cannot use the cumulative number(s) to generate our model. \n",
    "# But, realistic to use them as input during test/dev\n",
    "dev_num_reviews_by_user = num_reviews_by_user[['user_id','cumulative_total_train_dev_test_reviews']]\n",
    "dev_num_reviews_by_user.columns = ['user_id','num_user_reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev_num_reviews_by_prod = num_reviews_by_prod[['prod_id','cumulative_total_train_dev_test_reviews']]\n",
    "dev_num_reviews_by_prod.columns = ['prod_id','num_prod_reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev = pd.merge(dev, dev_num_reviews_by_user , on='user_id', how='left')\n",
    "dev = pd.merge(dev, dev_num_reviews_by_prod , on='prod_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTrainSet(i):\n",
    "    train_fname = '../../data/processed/dev/ac4119_train_set_{0}_w_tokens.csv'.format(i)\n",
    "    train = pd.read_csv(train_fname)\n",
    "    train['token_review'] = train['token_review'].apply(lambda x: literal_eval(x))\n",
    "    \n",
    "    train_num_reviews_by_user = num_reviews_by_user[['user_id','train_num_reviews']]\n",
    "    train_num_reviews_by_user.columns = ['user_id','num_user_reviews']\n",
    "    \n",
    "    train_num_reviews_by_prod = num_reviews_by_prod[['prod_id','train_num_reviews']]\n",
    "    train_num_reviews_by_prod.columns = ['prod_id','num_prod_reviews']\n",
    "    \n",
    "    train = pd.merge(train, train_num_reviews_by_user , on='user_id', how='left')\n",
    "    train = pd.merge(train, train_num_reviews_by_prod , on='prod_id', how='left')\n",
    "    return train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['rating', 'token_review', 'num_user_reviews', 'num_prod_reviews']\n",
    "X_dev = dev[feature_cols].fillna(0)\n",
    "Y_dev = dev['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainModel(params, X_train, Y_train):\n",
    "    # Defining tfidf params\n",
    "    tfidf_vectorizer = TfidfVectorizer(tokenizer=identity_tokenizer, decode_error='ignore',\n",
    "                                           stop_words='english', \n",
    "                                           lowercase=False, binary=True, \n",
    "                                           min_df=0.01)\n",
    "\n",
    "\n",
    "    # setting remainder to passthrough so that the remaining columns (i.e. rating) get included as-is \n",
    "    pipeline = Pipeline([\n",
    "        ('transformer',  make_column_transformer((StandardScaler(), ['num_user_reviews', 'num_prod_reviews']),\n",
    "                                                (tfidf_vectorizer, 'token_review'),\n",
    "                                                remainder = 'passthrough')),\n",
    "        ('fitted_svm', SGDClassifier(**params)),\n",
    "    ])\n",
    "\n",
    "    fitted_model = pipeline.fit(X_train, Y_train)\n",
    "    return fitted_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_attempts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sets = [1,3]\n",
    "losses = ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron']\n",
    "alphas = [0.00001, 0.000001, 0.1, 1, 10]\n",
    "sgd_params_combos = [(a,l,i) for a in alphas for l in losses for i in sets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/chuamelia/anaconda/envs/py35/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "for p in sgd_params_combos:\n",
    "    a,l,i = p\n",
    "    train = getTrainSet(i)\n",
    "    \n",
    "    feature_cols = ['rating', 'token_review', 'num_user_reviews', 'num_prod_reviews']\n",
    "    X_train = train[feature_cols].fillna(0)\n",
    "    Y_train = train['label']\n",
    "    \n",
    "    # Defining model params\n",
    "    params = {'alpha': a,\n",
    "      'class_weight': 'balanced',\n",
    "      'loss': l,\n",
    "      'penalty': 'l2',\n",
    "      'random_state': 519}\n",
    "    \n",
    "    fitted_model = trainModel(params, X_train, Y_train)\n",
    "    metrics = ClassifierMetrics(X_train, Y_train, X_dev, Y_dev, fitted_model)\n",
    "    model_attempt_details = {'params': params, 'metrics': metrics}\n",
    "\n",
    "    all_attempts.append(model_attempt_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully written to sgd_attempts_ac4119_202005119b\n"
     ]
    }
   ],
   "source": [
    "# File name of the model attempts/results\n",
    "fname = 'sgd_attempts_ac4119_202005119b'\n",
    "writeJsonFile(fname, all_attempts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'test_accuracy': 0.7536054346010357,\n",
       "  'test_ap_pred': 0.17080233911090023,\n",
       "  'test_ap_score': 0.23832333162772845,\n",
       "  'test_auc_pred': 0.6731094360766341,\n",
       "  'test_auc_score': 0.7591436138475255,\n",
       "  'train_accuracy': 0.6969918664199337},\n",
       " {'test_accuracy': 0.7132078623531377,\n",
       "  'test_ap_pred': 0.17235727048091248,\n",
       "  'test_ap_score': 0.24665313890511958,\n",
       "  'test_auc_pred': 0.6881914996275941,\n",
       "  'test_auc_score': 0.7601918808681141,\n",
       "  'train_accuracy': 0.7032319146189268},\n",
       " {'test_accuracy': 0.6531544072609834,\n",
       "  'test_ap_pred': 0.1677031606244063,\n",
       "  'test_ap_score': 0.23594724337006595,\n",
       "  'test_auc_pred': 0.6931855805457244,\n",
       "  'test_auc_score': 0.7570887971012129,\n",
       "  'train_accuracy': 0.6947540560313293},\n",
       " {'test_accuracy': 0.8046383428921432,\n",
       "  'test_ap_pred': 0.16282474902893246,\n",
       "  'test_ap_score': 0.23901825466984344,\n",
       "  'test_auc_pred': 0.6406052923795388,\n",
       "  'test_auc_score': 0.7561975454498503,\n",
       "  'train_accuracy': 0.6822309248181779},\n",
       " {'test_accuracy': 0.38754941811904897,\n",
       "  'test_ap_pred': 0.1332661489977715,\n",
       "  'test_ap_score': 0.20460702821647792,\n",
       "  'test_auc_pred': 0.6302241334083583,\n",
       "  'test_auc_score': 0.7240765535721081,\n",
       "  'train_accuracy': 0.5889314455394414},\n",
       " {'test_accuracy': 0.4346567180800713,\n",
       "  'test_ap_pred': 0.14291664553088432,\n",
       "  'test_ap_score': 0.22493489141015854,\n",
       "  'test_auc_pred': 0.6580208061504086,\n",
       "  'test_auc_score': 0.7510448521656635,\n",
       "  'train_accuracy': 0.6071566897620174},\n",
       " {'test_accuracy': 0.8654713514115485,\n",
       "  'test_ap_pred': 0.1323779919215256,\n",
       "  'test_ap_score': 0.2260390447181872,\n",
       "  'test_auc_pred': 0.5641988733357254,\n",
       "  'test_auc_score': 0.7444365302491587,\n",
       "  'train_accuracy': 0.6211645220983776},\n",
       " {'test_accuracy': 0.3707611782393229,\n",
       "  'test_ap_pred': 0.13278818546163657,\n",
       "  'test_ap_score': 0.2119331148208315,\n",
       "  'test_auc_pred': 0.6293907898814282,\n",
       "  'test_auc_score': 0.7358368552210245,\n",
       "  'train_accuracy': 0.573976847269441},\n",
       " {'test_accuracy': 0.8412773539729383,\n",
       "  'test_ap_pred': 0.15282950119606004,\n",
       "  'test_ap_score': 0.23671085204708436,\n",
       "  'test_auc_pred': 0.6079924764459957,\n",
       "  'test_auc_score': 0.7548534432610811,\n",
       "  'train_accuracy': 0.6479752119464647},\n",
       " {'test_accuracy': 0.8106241995656773,\n",
       "  'test_ap_pred': 0.1332614846693173,\n",
       "  'test_ap_score': 0.18832012550634464,\n",
       "  'test_auc_pred': 0.585584334344538,\n",
       "  'test_auc_score': 0.7207349396403155,\n",
       "  'train_accuracy': 0.6133752205534277},\n",
       " {'test_accuracy': 0.8398574530875884,\n",
       "  'test_ap_pred': 0.142803239844671,\n",
       "  'test_ap_score': 0.22139361682293265,\n",
       "  'test_auc_pred': 0.5927357795926911,\n",
       "  'test_auc_score': 0.7379808234659316,\n",
       "  'train_accuracy': 0.6494168782545079},\n",
       " {'test_accuracy': 0.8362102566958071,\n",
       "  'test_ap_pred': 0.13987949210464362,\n",
       "  'test_ap_score': 0.21132260976431005,\n",
       "  'test_auc_pred': 0.5893687920995547,\n",
       "  'test_auc_score': 0.7202168415887876,\n",
       "  'train_accuracy': 0.6480397641692129},\n",
       " {'test_accuracy': 0.39501085806559383,\n",
       "  'test_ap_pred': 0.13433381738353298,\n",
       "  'test_ap_score': 0.20396135519366368,\n",
       "  'test_auc_pred': 0.6334040599057296,\n",
       "  'test_auc_score': 0.723596290754,\n",
       "  'train_accuracy': 0.5931058226104919},\n",
       " {'test_accuracy': 0.43568684225179577,\n",
       "  'test_ap_pred': 0.14309164513450837,\n",
       "  'test_ap_score': 0.22456823982948523,\n",
       "  'test_auc_pred': 0.658472526897504,\n",
       "  'test_auc_score': 0.7509105770119442,\n",
       "  'train_accuracy': 0.6078237293970823},\n",
       " {'test_accuracy': 0.35661785177348404,\n",
       "  'test_ap_pred': 0.13056926925154652,\n",
       "  'test_ap_score': 0.20273215140114786,\n",
       "  'test_auc_pred': 0.6223706721385895,\n",
       "  'test_auc_score': 0.7234057129673425,\n",
       "  'train_accuracy': 0.564337048672376},\n",
       " {'test_accuracy': 0.5334094325964698,\n",
       "  'test_ap_pred': 0.13147404364596876,\n",
       "  'test_ap_score': 0.16952198656140569,\n",
       "  'test_auc_pred': 0.6163330982010341,\n",
       "  'test_auc_score': 0.6557132051930259,\n",
       "  'train_accuracy': 0.612622111288032},\n",
       " {'test_accuracy': 0.23929506097221448,\n",
       "  'test_ap_pred': 0.11532097704977348,\n",
       "  'test_ap_score': 0.16554800372636314,\n",
       "  'test_auc_pred': 0.5661953657190699,\n",
       "  'test_auc_score': 0.6710187208802918,\n",
       "  'train_accuracy': 0.5058097000473383},\n",
       " {'test_accuracy': 0.8884124951277911,\n",
       "  'test_ap_pred': 0.11186139066827,\n",
       "  'test_ap_score': 0.18497450977273458,\n",
       "  'test_auc_pred': 0.5209236995688789,\n",
       "  'test_auc_score': 0.679528760213984,\n",
       "  'train_accuracy': 0.5758918965443044},\n",
       " {'test_accuracy': 0.36956400690461605,\n",
       "  'test_ap_pred': 0.13246857535886977,\n",
       "  'test_ap_score': 0.210384810990624,\n",
       "  'test_auc_pred': 0.6283598349860551,\n",
       "  'test_auc_score': 0.7319701861078944,\n",
       "  'train_accuracy': 0.5701897835348797},\n",
       " {'test_accuracy': 0.8714572080850826,\n",
       "  'test_ap_pred': 0.12222113229374404,\n",
       "  'test_ap_score': 0.19175547394937964,\n",
       "  'test_auc_pred': 0.5454049219442314,\n",
       "  'test_auc_score': 0.6898738338525272,\n",
       "  'train_accuracy': 0.6039290786246073},\n",
       " {'test_accuracy': 0.3594298123503536,\n",
       "  'test_ap_pred': 0.1305269976533131,\n",
       "  'test_ap_score': 0.20073216620128131,\n",
       "  'test_auc_pred': 0.622112086072013,\n",
       "  'test_auc_score': 0.7192351387552396,\n",
       "  'train_accuracy': 0.5539226234023324},\n",
       " {'test_accuracy': 0.3541678267164096,\n",
       "  'test_ap_pred': 0.1297346072712225,\n",
       "  'test_ap_score': 0.1982571748822046,\n",
       "  'test_auc_pred': 0.6195483709952756,\n",
       "  'test_auc_score': 0.713478627765183,\n",
       "  'train_accuracy': 0.5552136678572965},\n",
       " {'test_accuracy': 0.5172336989810123,\n",
       "  'test_ap_pred': 0.15530890683595874,\n",
       "  'test_ap_score': 0.24039598851319488,\n",
       "  'test_auc_pred': 0.6851338962917055,\n",
       "  'test_auc_score': 0.7605661132902756,\n",
       "  'train_accuracy': 0.6339028273873564},\n",
       " {'test_accuracy': 0.5114427306642909,\n",
       "  'test_ap_pred': 0.15443242475066843,\n",
       "  'test_ap_score': 0.2395443706229563,\n",
       "  'test_auc_pred': 0.6834914615035419,\n",
       "  'test_auc_score': 0.7604639904397654,\n",
       "  'train_accuracy': 0.629556311055644},\n",
       " {'test_accuracy': 0.5490005011414889,\n",
       "  'test_ap_pred': 0.1616759163804499,\n",
       "  'test_ap_score': 0.24999122037329324,\n",
       "  'test_auc_pred': 0.697220766803125,\n",
       "  'test_auc_score': 0.7702898362364696,\n",
       "  'train_accuracy': 0.649653569737918},\n",
       " {'test_accuracy': 0.5059301742858734,\n",
       "  'test_ap_pred': 0.15405205630276708,\n",
       "  'test_ap_score': 0.2248746466929985,\n",
       "  'test_auc_pred': 0.6830980736140786,\n",
       "  'test_auc_score': 0.7595485799640097,\n",
       "  'train_accuracy': 0.6295778284632267},\n",
       " {'test_accuracy': 0.650565176234757,\n",
       "  'test_ap_pred': 0.11517619929495049,\n",
       "  'test_ap_score': 0.14519307434790643,\n",
       "  'test_auc_pred': 0.5571697937223754,\n",
       "  'test_auc_score': 0.6009919049250022,\n",
       "  'train_accuracy': 0.5651762275681026},\n",
       " {'test_accuracy': 0.6484492455036472,\n",
       "  'test_ap_pred': 0.11481271216206354,\n",
       "  'test_ap_score': 0.14394062470869903,\n",
       "  'test_auc_pred': 0.5559922294211668,\n",
       "  'test_auc_score': 0.5990916740740135,\n",
       "  'train_accuracy': 0.567005207212635},\n",
       " {'test_accuracy': 0.6429088479313994,\n",
       "  'test_ap_pred': 0.15811328266350014,\n",
       "  'test_ap_score': 0.20603524075917157,\n",
       "  'test_auc_pred': 0.6739897381061112,\n",
       "  'test_auc_score': 0.7275677670314614,\n",
       "  'train_accuracy': 0.673150578818264},\n",
       " {'test_accuracy': 0.3489893646639568,\n",
       "  'test_ap_pred': 0.1254618158056587,\n",
       "  'test_ap_score': 0.15902979637619008,\n",
       "  'test_auc_pred': 0.6043881565355906,\n",
       "  'test_auc_score': 0.6735028409554253,\n",
       "  'train_accuracy': 0.5534062056203468},\n",
       " {'test_accuracy': 0.4899214878333983,\n",
       "  'test_ap_pred': 0.1509436987021054,\n",
       "  'test_ap_score': 0.2149093528885875,\n",
       "  'test_auc_pred': 0.6763770784743857,\n",
       "  'test_auc_score': 0.754093272769777,\n",
       "  'train_accuracy': 0.6217885269182769},\n",
       " {'test_accuracy': 0.4785344395567682,\n",
       "  'test_ap_pred': 0.14922568181961113,\n",
       "  'test_ap_score': 0.21978011092227903,\n",
       "  'test_auc_pred': 0.6727144002223563,\n",
       "  'test_auc_score': 0.7562738190378331,\n",
       "  'train_accuracy': 0.6177002194775574},\n",
       " {'test_accuracy': 0.5389219889748872,\n",
       "  'test_ap_pred': 0.15781627863654604,\n",
       "  'test_ap_score': 0.22559102050678892,\n",
       "  'test_auc_pred': 0.6889373651047357,\n",
       "  'test_auc_score': 0.7525730337231364,\n",
       "  'train_accuracy': 0.6448336704393854},\n",
       " {'test_accuracy': 0.5485272008463723,\n",
       "  'test_ap_pred': 0.1590428559170594,\n",
       "  'test_ap_score': 0.23126484333652972,\n",
       "  'test_auc_pred': 0.6907574403062972,\n",
       "  'test_auc_score': 0.7547078956882445,\n",
       "  'train_accuracy': 0.6492232215862633},\n",
       " {'test_accuracy': 0.5015869480483323,\n",
       "  'test_ap_pred': 0.15252020378840633,\n",
       "  'test_ap_score': 0.24510900426576804,\n",
       "  'test_auc_pred': 0.6794652965793008,\n",
       "  'test_auc_score': 0.7635024213190242,\n",
       "  'train_accuracy': 0.6250591728708526},\n",
       " {'test_accuracy': 0.5026449134138872,\n",
       "  'test_ap_pred': 0.15255487651756508,\n",
       "  'test_ap_score': 0.23187964280798923,\n",
       "  'test_auc_pred': 0.679446243047967,\n",
       "  'test_auc_score': 0.7604471115424135,\n",
       "  'train_accuracy': 0.6250806902784353},\n",
       " {'test_accuracy': 0.6468901386491452,\n",
       "  'test_ap_pred': 0.11447861463840284,\n",
       "  'test_ap_score': 0.14006835210676266,\n",
       "  'test_auc_pred': 0.5548814161896064,\n",
       "  'test_auc_score': 0.5823937215598649,\n",
       "  'train_accuracy': 0.564250979042045},\n",
       " {'test_accuracy': 0.634779219332925,\n",
       "  'test_ap_pred': 0.11299744997015368,\n",
       "  'test_ap_score': 0.14552774859378936,\n",
       "  'test_auc_pred': 0.5499649170377136,\n",
       "  'test_auc_score': 0.5874488961014249,\n",
       "  'train_accuracy': 0.5611955071652968},\n",
       " {'test_accuracy': 0.7212818085639512,\n",
       "  'test_ap_pred': 0.12279398375874348,\n",
       "  'test_ap_score': 0.14890494119914516,\n",
       "  'test_auc_pred': 0.5759803861606294,\n",
       "  'test_auc_score': 0.6415977409630367,\n",
       "  'train_accuracy': 0.5924603003830099},\n",
       " {'test_accuracy': 0.6353638844033632,\n",
       "  'test_ap_pred': 0.12605125509913398,\n",
       "  'test_ap_score': 0.14672615346388673,\n",
       "  'test_auc_pred': 0.5927172272465329,\n",
       "  'test_auc_score': 0.6428216606456488,\n",
       "  'train_accuracy': 0.5914489822266213},\n",
       " {'test_accuracy': 0.8796982014588786,\n",
       "  'test_ap_pred': 0.1255943178082797,\n",
       "  'test_ap_score': 0.20899992825663338,\n",
       "  'test_auc_pred': 0.546101076647693,\n",
       "  'test_auc_score': 0.7316565631133147,\n",
       "  'train_accuracy': 0.5939665189138013},\n",
       " {'test_accuracy': 0.8861851996213598,\n",
       "  'test_ap_pred': 0.11770042269952781,\n",
       "  'test_ap_score': 0.21038526101109944,\n",
       "  'test_auc_pred': 0.5307467676104578,\n",
       "  'test_auc_score': 0.7329416188926764,\n",
       "  'train_accuracy': 0.5861341825536859},\n",
       " {'test_accuracy': 0.8520797371791302,\n",
       "  'test_ap_pred': 0.1309097898999008,\n",
       "  'test_ap_score': 0.2172884525243164,\n",
       "  'test_auc_pred': 0.5679303073981048,\n",
       "  'test_auc_score': 0.7430934134414127,\n",
       "  'train_accuracy': 0.602164651202823},\n",
       " {'test_accuracy': 0.8721810791246729,\n",
       "  'test_ap_pred': 0.12934769152990042,\n",
       "  'test_ap_score': 0.22151135577095948,\n",
       "  'test_auc_pred': 0.5560194123459408,\n",
       "  'test_auc_score': 0.7465609607668847,\n",
       "  'train_accuracy': 0.6028532082454706},\n",
       " {'test_accuracy': 0.5571022885461329,\n",
       "  'test_ap_pred': 0.1609105446642787,\n",
       "  'test_ap_score': 0.2211784902995262,\n",
       "  'test_auc_pred': 0.6941924360793524,\n",
       "  'test_auc_score': 0.7551019121828433,\n",
       "  'train_accuracy': 0.6525153849464217},\n",
       " {'test_accuracy': 0.6014811515117768,\n",
       "  'test_ap_pred': 0.1675649014365066,\n",
       "  'test_ap_score': 0.23467263549897321,\n",
       "  'test_auc_pred': 0.7028434358673257,\n",
       "  'test_auc_score': 0.7600666270475538,\n",
       "  'train_accuracy': 0.6725696088135301},\n",
       " {'test_accuracy': 0.5083801993429479,\n",
       "  'test_ap_pred': 0.15302337981771413,\n",
       "  'test_ap_score': 0.21963017768041487,\n",
       "  'test_auc_pred': 0.6800851522107874,\n",
       "  'test_auc_score': 0.7451885798416866,\n",
       "  'train_accuracy': 0.6280285751172698},\n",
       " {'test_accuracy': 0.5650648699816249,\n",
       "  'test_ap_pred': 0.16215604662991429,\n",
       "  'test_ap_score': 0.2335983537436842,\n",
       "  'test_auc_pred': 0.6960708866118659,\n",
       "  'test_auc_score': 0.7610849588722347,\n",
       "  'train_accuracy': 0.6584111546240909},\n",
       " {'test_accuracy': 0.6250626426861183,\n",
       "  'test_ap_pred': 0.12356578933330381,\n",
       "  'test_ap_score': 0.15188338986554453,\n",
       "  'test_auc_pred': 0.5858902441842133,\n",
       "  'test_auc_score': 0.6248641618281061,\n",
       "  'train_accuracy': 0.5806042088049231},\n",
       " {'test_accuracy': 0.6779330697700318,\n",
       "  'test_ap_pred': 0.12020560940375657,\n",
       "  'test_ap_score': 0.1497865051154715,\n",
       "  'test_auc_pred': 0.5720359568933178,\n",
       "  'test_auc_score': 0.6264688038561698,\n",
       "  'train_accuracy': 0.5827344321556139}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_attempts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply to test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_fname = '../../data/processed/dev/ac4119_test_set_w_tokens.csv'\n",
    "test = pd.read_csv(test_fname)\n",
    "test_num_reviews_by_prod = num_reviews_by_prod[['prod_id','cumulative_total_train_dev_test_reviews']]\n",
    "test_num_reviews_by_prod.columns = ['prod_id','num_prod_reviews']\n",
    "\n",
    "test_num_reviews_by_user = num_reviews_by_user[['user_id','cumulative_total_train_dev_test_reviews']]\n",
    "test_num_reviews_by_user.columns = ['user_id','num_user_reviews']\n",
    "\n",
    "test = pd.merge(test, test_num_reviews_by_user , on='user_id', how='left')\n",
    "test = pd.merge(test, test_num_reviews_by_prod , on='prod_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['token_review'] = test['token_review'].apply(lambda x: literal_eval(x))\n",
    "\n",
    "feature_cols = ['rating', 'token_review', 'num_user_reviews', 'num_prod_reviews']\n",
    "X_test = test[feature_cols].fillna(0)\n",
    "\n",
    "Y_test = test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = fitted_model.predict(X_test)\n",
    "Y_score = fitted_model.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['Y_score'] = Y_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = test[['ex_id', 'Y_score']].sort_values(by='ex_id', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = '/Users/chuamelia/Google Drive/Spring 2020/Machine Learning/fake-review-detection-project/predictions.csv'\n",
    "predictions['Y_score'].to_csv(fname, header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
